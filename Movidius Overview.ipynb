{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intel Neural Compute Stick - Movidius\n",
    "\n",
    "Intel's Movidius™ Myriad™ 2 VPU is an industry-defining always-on vision processor, and second generation VPU from Movidius™, an Intel® company. Myriad 2 can be found in millions of devices on the market today and continues to be utilized for some of the most ambitious AI, vision and imaging applications where both performance and low power consumption are \n",
    "\n",
    "![](resources/myriad_vpu.png)\n",
    "\n",
    "Standing at the intersection of low-power and high performance, the Myriad 2 family of processors are transforming the capabilities of devices. Myriad 2 gives device makers industry-proven performance on AI, imaging and computer vision tasks, all at an unbeatable performance/price proposition.\n",
    "\n",
    "The Intel® Movidius™ Neural Compute Stick (Intel® Movidius™ NCS) enables rapid prototyping of deep neural networks (DNNs) with the Intel® Movidius™ Neural Compute SDK (NCSDK).\n",
    "\n",
    "![](resources/ncs.jpg)\n",
    "\n",
    "Images from: https://movidius.github.io/ncsdk/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Myriad VPU includes 4Gbits of LPDDR3 DRAM, imaging and vision accelerators, and an array of 12 VLIW vector processors called SHAVE processors. \n",
    "\n",
    "These processors are used to accelerate neural networks by running parts of the neural networks in parallel.\n",
    "\n",
    "The NCS is connected to a host machine using the USB interface on the VPU. The USB3 interface can be used both in Super Speed (5 Gbps) or High Speed (480 Mbps) modes.\n",
    "\n",
    "![](resources/ncs_architecture.jpg)\n",
    "\n",
    "The VPU also has a SPARC microprocessor core that runs custom firmware. When the NCS is first plugged in, there is no firmware loaded onto it. The VPU boots from the internal ROM and connects to the host machine as a USB 2.0 device. \n",
    "\n",
    "Applications executing on the host machine communicate to the VPU SOC using the Neural Compute API (NCAPI). When the NCAPI initializes and opens a device, the firmware from the Neural Compute SDK (NCSDK) is loaded onto the NCS. At this time, the NCS resets and reconnects to the host machine as either a USB 2.0 or USB 3.0 device (depending on the host type). It is now ready to accept the neural network graph files and instructions to execute inferences.\n",
    "\n",
    "A graph file is loaded into the DRAM attached to the VPU via the NCAPI. A LEON processor coordinates receiving the graph file and images for inference via the USB connection. \n",
    "\n",
    "It also parses the graph file and schedules kernels to the SHAVE neural compute accelerator engines. In addition, the LEON processor also takes care of monitoring die temperature and throttling processing on high temperature alerts. \n",
    "\n",
    "The output of the neural network and associated statistics are sent back to the host machine via the USB connection and are received by the host application via the NCAPI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intel Neural Compute Stick SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Intel® Movidius™ Neural Compute SDK](https://github.com/movidius/ncsdk) provides tools for profiling, tuning, and compiling a deep neural network (DNN) model on a development computer (host system).\n",
    "\n",
    "In order to develop applications using Movidius NCS Stick you should install tools and SDK as following.\n",
    "\n",
    "In order to install it on Ubuntu 16.04, clone the sdk from github repo:\n",
    "\n",
    "Check following url for installation instructions: https://github.com/movidius/ncsdk\n",
    "\n",
    "### NCSDK Installation Instructions\n",
    "\n",
    "```shell\n",
    "\n",
    "git clone https://github.com/movidius/ncsdk.git \n",
    "\n",
    "```\n",
    "or get version 2 from ncsdk2 branch. v2 is not back compatible.\n",
    "\n",
    "```shell\n",
    "\n",
    "git clone -b ncsdk2 https://github.com/movidius/ncsdk.git\n",
    "\n",
    "cd ncsdk && make install\n",
    "\n",
    "```\n",
    "\n",
    "After installation, you can get a set of examples from SDK App Zoo:\n",
    "\n",
    "```shell\n",
    "\n",
    "git clone https://github.com/movidius/ncappzoo.git\n",
    "\n",
    "```\n",
    "\n",
    "or NCSDK v2\n",
    "\n",
    "```shell\n",
    "\n",
    "git clone -b ncsdk2 https://github.com/movidius/ncappzoo.git\n",
    "\n",
    "```\n",
    "\n",
    "You will see set of applications under `ncappzoo/app/` folder. \n",
    "\n",
    "Navigate to any of application folder, and run `make`, which downloads required models and video resources to run the application as shown below.\n",
    "\n",
    "```shell\n",
    "\n",
    "cd ncappzoo/apps/video_objects\n",
    "\n",
    "make \n",
    "\n",
    "python3 video_objects.py\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start from Scratch with NCSDK\n",
    "\n",
    "Like all dedicated hardwares, Myriad VPU should get neural net's with its own format. Therefore NCSDK application `mvNCCompile` is provided with SDK to convert existing Caffe or Tensorflow models to required graph file with certain set of parameters to load them on Movidius.\n",
    "\n",
    "`\n",
    "mvNCCompile is a command line tool that compiles network and weights files for Caffe or TensorFlow* models into an Intel® Movidius™ graph file format that is compatible with the Intel® Movidius™ Neural Compute SDK (Intel® Movidius™ NCSDK) and Neural Compute API (NCAPI).\n",
    "`\n",
    "\n",
    "Please see following documentation for arguments details: https://movidius.github.io/ncsdk/tools/compile.html\n",
    "\n",
    "Required input is neural net file: \n",
    "`.prototxt` and `.caffemodel` for Caffe models\n",
    "`.pb` or `.meta` for Tensorflow models\n",
    "\n",
    "\n",
    "`-w` defines the weights, .caffemodel for Caffe Framework Model\n",
    "\n",
    "`-s` The number of available SHAVEs depends on your neural compute device. The device runtime code may use fewer SHAVEs for some layers where measurements have typically shown no inference performance degradation (and consequently show a power benefit) from using fewer SHAVEs.\n",
    "\n",
    "`-is` Specify input dimensions for networks that do not have dimension constraints on the input layer.\n",
    "\n",
    "Caffe Model Conversion Sample\n",
    "```shell\n",
    "mvNCCompile dnn_models/MobileNetSSD_deploy.prototxt -w dnn_models/MobileNetSSD_deploy.caffemodel -s 12 -is 300 300 -o MobileNetSSD.graph\n",
    "```\n",
    "\n",
    "Tensorflow Sample (Not working example, fix it later)\n",
    "```shell\n",
    "mvNCCompile inception-v1.meta -s 12 -in=input  -is 300 300 -o frozen.graph\n",
    "```\n",
    "\n",
    "#### mvNCCheck\n",
    "\n",
    "`mvNCCheck` is a command line tool that checks the validity of a Caffe or TensorFlow* neural network on a neural compute device.\n",
    "\n",
    "The check is done by running an inference on both the device and in software on the host computer using the supplied network and appropriate framework libraries. The results for both inferences are compared to determine a if the network passes or fails. The top 5 inference results are provided as output. This tool works best with image classification networks.\n",
    "\n",
    "#### mvNCProfile\n",
    "\n",
    "`mvNCProfile` is a command line tool that compiles a network for use with the Intel® Movidius™ Neural Compute SDK (Intel® Movidius™ NCSDK), runs the network on a connected neural compute device, and outputs text and HTML profile reports.\n",
    "\n",
    "The profiling data contains layer-by-layer statistics about the performance of the network. This is helpful in determining how much time is spent on each layer to narrow down potential changes to the network to improve the total inference time.\n",
    "\n",
    "\n",
    "#### NCSDK API \n",
    "\n",
    "A quick overview of NC SDK Overview: \n",
    "https://movidius.github.io/ncsdk/ncapi/ncapi2/c_api/readme.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection with  Movidius using Python API\n",
    "\n",
    "Below sample uses converted Caffe Model and loads it to Movidius for object detection.\n",
    "\n",
    "For more comprehensive example refer to [RealTimeObjectDetection.py](RealTimeObjectDetection.py) code sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import sys\n",
    "# import NCSDK as below\n",
    "#import mvnc\n",
    "\n",
    "#import MVNC for Movidius Support\n",
    "sys.path.insert(0, \"/home/intel/Intel/ncappzoo/ncapi2_shim\")\n",
    "import mvnc_simple_api as mvnc\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# get attached devices\n",
    "\n",
    "devices = mvnc.EnumerateDevices()\n",
    "\n",
    "print('Number of Attached Devices {} '.format(len(devices)))\n",
    "\n",
    "# pick device\n",
    "device = mvnc.Device(devices[0])\n",
    "\n",
    "labels = (\"background\", \"aeroplane\", \"bicycle\",\n",
    "                \"bird\", \"boat\", \"bottle\", \"bus\",\n",
    "                \"car\", \"cat\", \"chair\", \"cow\",\n",
    "                \"diningtable\", \"dog\", \"horse\",\n",
    "                \"motorbike\", \"person\", \"pottedplant\",\n",
    "                \"sheep\", \"sofa\", \"train\", \"tvmonitor\")\n",
    "\n",
    "label_colors = np.random.uniform(0, 255, (len(labels), 3))\n",
    "\n",
    "with open('dnn_models/MobileNetSSD_Caffe.graph', mode='rb') as f:\n",
    "    graph_data = f.read()\n",
    "    \n",
    "movidius_graph = device.AllocateGraph(graph_data) \n",
    "\n",
    "img = cv.imread('resources/street.jpg')\n",
    "\n",
    "resized_image = cv.resize(img, (300, 300))\n",
    "\n",
    "# trasnform values from range 0-255 to range -1.0 - 1.0q\n",
    "resized_image = resized_image - 127.5\n",
    "resized_image = resized_image * 0.007843\n",
    "\n",
    "movidius_graph.LoadTensor(resized_image.astype(np.float16), None)\n",
    "\n",
    "output, userobj = movidius_graph.GetResult()\n",
    "\n",
    "num_valid_boxes = int(output[0])\n",
    "print('Number of Valid Detections {}'.format(num_valid_boxes))\n",
    "\n",
    "actual_frame_width = img.get(cv.CAP_PROP_FRAME_WIDTH)\n",
    "actual_frame_height = img.get(cv.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "for box_index in range(num_valid_boxes):\n",
    "    base_index = 7 + box_index * 7\n",
    "    if (not np.isfinite(output[base_index]) or\n",
    "            not np.isfinite(output[base_index + 1]) or\n",
    "            not np.isfinite(output[base_index + 2]) or\n",
    "            not np.isfinite(output[base_index + 3]) or\n",
    "            not np.isfinite(output[base_index + 4]) or\n",
    "            not np.isfinite(output[base_index + 5]) or\n",
    "            not np.isfinite(output[base_index + 6])):\n",
    "        # boxes with non finite (inf, nan, etc) numbers must be ignored\n",
    "        continue\n",
    "\n",
    "    left = max(int(output[base_index + 3] * 300), 0)\n",
    "    top = max(int(output[base_index + 4] * 300), 0)\n",
    "    right = min(int(output[base_index + 5] * 300), 300 - 1)\n",
    "    bottom = min((output[base_index + 6] * 300), 300 - 1)\n",
    "\n",
    "    object_info = output[base_index:base_index + 7]\n",
    "\n",
    "    base_index = 0\n",
    "\n",
    "    class_id = int(object_info[base_index + 1])\n",
    "    if class_id < 0:\n",
    "        continue\n",
    "\n",
    "    percentage = object_info[base_index + 2]\n",
    "\n",
    "    if percentage >= 0.6:\n",
    "        #print(percentage)\n",
    "        # overlay boxes and labels on to the image\n",
    "        # original image\n",
    "        row_factor = actual_frame_height / 300.0\n",
    "        col_factor = actual_frame_width / 300.0\n",
    "\n",
    "        # Scale object detection to original image\n",
    "        left = int(col_factor * left)\n",
    "        top = int(row_factor * top)\n",
    "        right = int(col_factor * right)\n",
    "        bottom = int(row_factor * bottom)\n",
    "        # display text to let user know how to quit\n",
    "        \n",
    "        label_text = labels[class_id] + \" \" + str(round(percentage, 4))\n",
    "        \n",
    "        cv.putText(img, label_text, (int(left), int(top)), cv.FONT_HERSHEY_SIMPLEX, 0.5, label_colors[class_id], 2)\n",
    "        cv.rectangle(img, (int(left), int(top)), (int(right), int(bottom)), label_colors[class_id], thickness=3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Time Object Detection\n",
    "\n",
    "You can continue to run RealTimeObjectDetection.py example with following options to see its performance with OpenCV and inferrence with Movidius:\n",
    "\n",
    "1. Runs with a usb webcam, tries to infer all the incoming frames using MobileNetSDD Caffe Model\n",
    "\n",
    "```shell\n",
    "python RealTimeOBjectDetection.py -d movidius -i live -f caffe --mconfig dnn_models/MobileNetSSD_deploy.prototxt --mweight dnn_models/MobileNetSSD_deploy.caffemodel --mlabels dnn_models/caffe_ssd_labels.txt --model_image_height 300 --model_image_width 300 -c 0.65 \n",
    "```\n",
    "\n",
    "2. Runs with a usb webcam, tries to infer only 4 frames within the incoming frames per second using MobileNetSDD Caffe Model\n",
    "\n",
    "```shell\n",
    "python RealTimeOBjectDetection.py -d movidius -i live -f caffe --mconfig dnn_models/MobileNetSSD_deploy.prototxt --mweight dnn_models/MobileNetSSD_deploy.caffemodel --mlabels dnn_models/caffe_ssd_labels.txt --model_image_height 300 --model_image_width 300 -c 0.65 --infer_fc 4\n",
    "```\n",
    "\n",
    "3. Reads frames from .mp4 file and infers 4 frames per second.\n",
    "\n",
    "```shell\n",
    "python RealTimeOBjectDetection.py -d movidius -i offline -s resources/video.mp4 -f caffe --mconfig dnn_models/MobileNetSSD_deploy.prototxt --mweight dnn_models/MobileNetSSD_deploy.caffemodel --mlabels dnn_models/caffe_ssd_labels.txt --model_image_height 300 --model_image_width 300 -c 0.65 --infer_fc 4\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
